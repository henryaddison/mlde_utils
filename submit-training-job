#!/bin/env python

import argparse
from datetime import datetime
import subprocess
import yaml

parser = argparse.ArgumentParser(description='Submit a training job to Slurm on BluePebble',
                                    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--dataset', dest='dataset_name', type=str, required=True,
                    help='Name of dataset to use for training')
parser.add_argument('--model', dest='model_name', type=str, required=True,
                    help='Name of model to use for training')
parser.add_argument('--loss', type=str, default='l1', help='Loss function')
parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
parser.add_argument('--batch-size', dest='batch_size', type=int, default=64, help='Batch size')
args = parser.parse_args()

jobname = f"{args.model_name}-{args.dataset_name}-{args.loss}-{args.epochs}-epochs"

train_basecmd = ["python", f"train-model.py"]
train_opts = {
    "--arch": args.model_name,
    "--data": f"${{WORK}}/nc-datasets/{args.dataset_name}",
    "--loss": args.loss,
    "--epochs": str(args.epochs),
    "--batch-size": "64",
    "--model": f"${{WORK}}/checkpoints/{args.model_name}/${{SLURM_JOB_ID}}"
}

train_cmd = train_basecmd + [arg for item in train_opts.items() for arg in item]

queue_opts = {
    "-m": "16",
    "-g": "1",
    "--queue": "cnu",
    "--condaenv": "cuda-downscaling",
    "--jobname": jobname,
    "--workdir": "~/code/ml-downscaling-emulation/"
}

queue_basecmd = ["lbatch"]
queue_cmd = queue_basecmd +  [arg for item in queue_opts.items() for arg in item]

full_cmd = queue_cmd + ["--cmd"] + [f"'{' '.join(train_cmd)}'"]

output = subprocess.run(full_cmd, capture_output=True)
stdout = output.stdout.decode("utf8")
print(stdout)
print(output.stderr.decode("utf8"))

job_id = int(stdout.replace("Submitted batch job ", ""))

experiments_log_filepath = 'experiments.yml'

with open(experiments_log_filepath, 'r') as file:
    experiments = yaml.safe_load(file)

experiments[jobname] = {"cmd": " ".join(full_cmd), "job_id": job_id, "submitted": datetime.now().strftime('%Y-%m-%d %H:%M')}

with open(experiments_log_filepath, 'w') as file:
    yaml.dump(experiments, file, sort_keys=False)
